{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjalko/Computer_Vision/blob/main/RNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMDZwtJPX4tS",
        "outputId": "4349e12c-0747-48b0-a5ef-105a79a8655c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels) , (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr28GNSvf3vL"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTN5DKHmd8c3"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = pad_sequences(train_data, MAXLEN)\n",
        "test_data = pad_sequences(test_data, MAXLEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKO7Lx68eh-y"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coYNRuvDl11o",
        "outputId": "b73f1899-3d66-4104-a250-057d377c8a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          2834688   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,836,801\n",
            "Trainable params: 2,836,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGN145n2jx3y",
        "outputId": "5e39eccc-d04f-4a78-ed12-c234a0ae57c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 30s 45ms/step - loss: 0.5165 - acc: 0.7363 - val_loss: 0.4353 - val_acc: 0.8290\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.3283 - acc: 0.8688 - val_loss: 0.4040 - val_acc: 0.8136\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.2433 - acc: 0.9056 - val_loss: 0.4336 - val_acc: 0.8106\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 27s 44ms/step - loss: 0.1767 - acc: 0.9337 - val_loss: 0.4113 - val_acc: 0.8292\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.1232 - acc: 0.9558 - val_loss: 0.5003 - val_acc: 0.8138\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 27s 44ms/step - loss: 0.0805 - acc: 0.9709 - val_loss: 0.4734 - val_acc: 0.8492\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.0586 - acc: 0.9804 - val_loss: 0.5237 - val_acc: 0.8404\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.6372 - val_acc: 0.8194\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 26s 42ms/step - loss: 0.0231 - acc: 0.9924 - val_loss: 0.8521 - val_acc: 0.7734\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 26s 42ms/step - loss: 0.0169 - acc: 0.9952 - val_loss: 0.7388 - val_acc: 0.8272\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"binary_crossentropy\" , optimizer=\"rmsprop\", metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels , epochs=10 , validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qYQjssk4lzic",
        "outputId": "ca9f0627-9138-4bdb-86db-60a8170a9ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7931 - acc: 0.8244\n",
            "[0.7930771112442017, 0.8244400024414062]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TGaUXRjbcxLB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.utils import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PBJBgFuBc16C",
        "outputId": "95695402-cc29-4be0-ccf3-8781052747e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return pad_sequences([tokens],  MAXLEN)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "obDnnHVmi0tr",
        "outputId": "cc9086c3-b667-4c07-b1cb-5634ac1c9b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0   75   17  111   13\n",
            "  853    8   83  317   92  432   43    4 2005    8    0  317]\n"
          ]
        }
      ],
      "source": [
        "text = \"bad movie , plot was average in first half , then went out of context in secand half\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dx0oyfYmi1Lh"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "czHZKE4xpmDR",
        "outputId": "327709aa-fab3-48b5-aa8b-24087dcd4bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 139ms/step\n",
            "[0.00540966]\n"
          ]
        }
      ],
      "source": [
        "predict(text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQgDM5N1U7rWuOvPDSmpXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}